Question 150- How to Implement SCD1 Type in Data Flows?
CREATE TABLE SCD_Type1_Emp (
    EmpID INT,    
    Name VARCHAR(100), 
    Country VARCHAR(50) , 
    Department VARCHAR(50) 
);

-- Insert sample rows
INSERT INTO SCD_Type1_Emp (EmpID, Name, Country, Department)
VALUES
    (101, 'Amit Sharma', 'India', 'IT'),
    (102, 'Ashwini Singh', 'India', 'Electronic');

select * from SCD_Type1_Emp;
--Add some records
106, Anjali Mehta, India, Computer
107, Mahesh Iche, US, Service Desk
108, Mayur Shinde, UK, Software
109, Sagar Kale, US, Service Desk
===============================================================================================================
Question 151- How to Implement SCD2 Type in Data Flows?

--Create table for SCD_Type2 Query
    CREATE TABLE SCD_Type2_Emp (
        SurrogateKey int identity,
        EmpID INT,
        EmpName NVARCHAR(100),
        Gender NVARCHAR(10),
        Country NVARCHAR(50),
        IsActive int
    );
    insert into SCD_Type2_Emp values(101, 'Rahul Singh','Male','India',1)
    select * from SCD_Type2_Emp;

===============================================================================================================

Question- Create two NoteBooks one Note Book Create Employee Dataframe,Second NoteBook Create Dept dataframe, in Second Note Join Dept daaframe with Emp Dataframe?

# Create the Employee DataFrame
from pyspark.sql.types import StructType, StructField, StringType, IntegerType

# Define schema for Employee DataFrame
emp_schema = StructType([
    StructField("emp_id", IntegerType(), True),
    StructField("emp_name", StringType(), True),
    StructField("dept_id", IntegerType(), True)
])

# Sample employee data
emp_data = [
    (1, "Alice", 101),
    (2, "Bob", 102),
    (3, "Charlie", 101),
    (4, "David", 103)
]

# Create Employee DataFrame
emp_df = spark.createDataFrame(data=emp_data, schema=emp_schema)

# Display the Employee DataFrame
emp_df.show()

---------------------

# Create the Department DataFrame

from pyspark.sql.types import StructType, StructField, StringType, IntegerType

# Define schema for Department DataFrame
dept_schema = StructType([
    StructField("dept_id", IntegerType(), True),
    StructField("dept_name", StringType(), True)
])

# Sample department data
dept_data = [
    (101, "HR"),
    (102, "Engineering"),
    (103, "Marketing")
]

# Create Department DataFrame
dept_df = spark.createDataFrame(data=dept_data, schema=dept_schema)

# Display the Department DataFrame
dept_df.show()
=====================================================================================
# Schema evolution

from pyspark.sql.types import StructType, StructField, StringType, IntegerType

# Sample data
data = [
    (1, "John","test_data")
]

# Define schema for DataFrame
schema = StructType([
    StructField("ID", IntegerType(), True),
    StructField("Name", StringType(), True),
    StructField("additional_column1", StringType(), True)
])

# Create DataFrame
df = spark.createDataFrame(data, schema)

# Show DataFrame
display(df)
